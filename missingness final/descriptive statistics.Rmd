---
title: "Traffic stop missingness statistics"
author: "Amber Lee"
date: "10/19/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Libraries

```{r load libraries, message = FALSE}

library(RMySQL)

library(tidyverse)
library(tidyr)
# library(broom) # make tidy the regression outputs
# library(lubridate) # dates
library(stringr) # string manipulation
# library(tidycensus)
# library(kableExtra) # make nice tables
library(ggrepel)
# library(geofacet)
# library(naniar) # replace "NA" with NA, except too slow, use baseR solution
# library(revgeo)

```


# Querying Data

```{r connect to sql, include = FALSE}

con <- dbConnect(
  MySQL(), host = "traffic.st47s.com", user = "student", 
  password = "Sagehen47", dbname = "traffic")

```

```{r query n% sample of all datasets}

dataset_names <- dbGetQuery(con, "SHOW TABLES")[[1]]

# remove datasets with "_" in the name
dataset_names <- dataset_names[str_detect(dataset_names, "_", negate = TRUE)]

query_sample <- function(dataset_str, percent){
  # input is dataset_str (str) with dataset name, and percent (dbl) for the random sample %
  # output is the dataframe with a column added for the name of dataset and character NA's
  # replaced with NA's
  # global variable con is the SQL connection
  
  command <- paste("SELECT * FROM", dataset_str, "WHERE rand() <=", percent, 
                   # in SQL, filter for vehicular stops
                   " AND type = 'vehicular'",
                   sep = " ")

  df <- dbGetQuery(con, command) %>% mutate(dataset_name = dataset_str)
  
  # do not consider empty datasets
  if (dim(df)[1] == 0){
    return(NULL)
  }
  
  # replace character NA's with NA
  if (sum(is.na(df) == 0)){
    
    df[df == "NA"] = NA

  }
  
  return(df %>% dplyr::select(-type))
  
}

dataset_lst <- lapply(dataset_names, query_sample, 0.3)

# remove empty datasets through logical indexing
dataset_lst <- dataset_lst[sapply(dataset_lst, function(x) isTRUE(nrow(x) > 0))]

```

# Cleaning data

Some columns are empty for all observations, so we want to remove them.

```{r}

check_nonempty <- function(var, dataset, n_obsv){
  # helper function for removing empty columns
    
  # the function environment has the parameter dataset
  col_str <- paste("dataset$", var, sep = "")
  col <- eval(parse(text = col_str))
  isCollected <- sum(is.na(col)) < n_obsv
  
  return(isCollected)
  
}

remove_empty_col <- function(dataset){
  # a variable is 'collected' if there is a column for it in the dataset
  # but being collected doesn't imply nonempty
  
  collected_var <- names(dataset)
  n_obsv <- dim(dataset)[1]
  
  nonempty_bools <- unlist(lapply(collected_var, check_nonempty, dataset, n_obsv))
  
  # use logial indexing!
  nonempty_var <- collected_var[nonempty_bools]
  
  ## in case i need this information
  # empty_var <- collected_var[!nonempty_bools]
  
  return(dataset %>% dplyr::select({{ nonempty_var }}))
  
}

dataset_lst <- lapply(dataset_lst, remove_empty_col)

```


# Functions for manipulating a list of dataframes

`myfilter_for` can be thought of as -- I have a list of dataframes, and I am *filtering for* these particular variables in each dataframe. If I *need containment*, then I only look for the dataframes with ALL of the variables in  `var_vect`. 

```{r}

myfilter_for <- function(dataset, var_vect, need_containment){
  # if need_containment is true, then function only returns
  # datasets containing ALL variables specified in var_vect
  
  # need_containment = TRUE results in more restrictive filtering
  
  dataset_var <- names(dataset)
  intersection <- var_vect[var_vect %in% dataset_var]
  
  if (need_containment){
    
    if (length(intersection) == length(var_vect)) {
      # embrace syntax from dplyr programming
      return(dataset %>% dplyr::select({{ var_vect }}))
    } else {
      return(NULL)
    }
    
  } else if (!need_containment){
    
    if (length(intersection > 0)) {
      # embrace syntax from dplyr programming
      return(dataset %>% dplyr::select({{ intersection }}))
    } else{
      return(NULL)
    }
    
  }
  
}

```

# Missingness in `search_conducted`

```{r}
sc_dataset_lst <- lapply(dataset_lst, myfilter_for, c("search_conducted", "dataset_name"), TRUE)
sc_dataset_lst <- sc_dataset_lst[sapply(sc_dataset_lst, 
                                        function(x) isTRUE(nrow(x) > 0))]
```

```{r}
sum(unlist(lapply(sc_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))>= 0.2)

sapply(sc_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, paste(x$dataset_name, as.character(dim(x)[1])), "nah"))
```

# Missingness in `arrest_made`

```{r}
ar_dataset_lst <- lapply(dataset_lst, myfilter_for, c("arrest_made", "dataset_name"), TRUE)
ar_dataset_lst <- ar_dataset_lst[sapply(ar_dataset_lst, 
                                        function(x) isTRUE(nrow(x) > 0))]
```

```{r}
hist(unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])))


```
```{r}
unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
```


# Missingness in `driver_race`

```{r}
race_dataset_lst <- lapply(dataset_lst, myfilter_for, c("subject_race", "dataset_name"), TRUE)
race_dataset_lst <- race_dataset_lst[sapply(race_dataset_lst, 
                                        function(x) isTRUE(nrow(x) > 0))]
```

```{r}
hist(unlist(lapply(race_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])))


```

```{r}
sum(unlist(lapply(race_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))>= 0.2)

sapply(race_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, paste(x$dataset_name, as.character(dim(x)[1])), "nah"))
```

```{r}
lapply(dataset_lst, function(x) names(x))
```

