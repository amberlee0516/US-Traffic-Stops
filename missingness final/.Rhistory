knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# cache=TRUE
con <- dbConnect(
MySQL(), host = "traffic.st47s.com", user = "student",
password = "Sagehen47", dbname = "traffic")
library(RMySQL)
library(tidyverse)
library(broom)
library(lubridate)
library(stringr)
library(kableExtra)
library(grid)
library(gridExtra)
library(patchwork)
library(XML)
library(RCurl)
library(lutz)
library(suncalc)
con <- dbConnect(
MySQL(), host = "traffic.st47s.com", user = "student",
password = "Sagehen47", dbname = "traffic")
dataset_names <- dbGetQuery(con, "SHOW TABLES")[[1]]
# remove datasets with "_" in the name
dataset_names <- dataset_names[str_detect(dataset_names, "_", negate = TRUE)]
query_sample <- function(dataset_str, percent){
# input is dataset_str (str) with dataset name, and percent (dbl) for the random sample %
# output is the dataframe with a column added for the name of dataset and character NA's
# replaced with NA's
# global variable con is the SQL connection
command <- paste("SELECT * FROM", dataset_str, "WHERE rand() <=", percent,
# in SQL, filter for vehicular stops
" AND type = 'vehicular'",
sep = " ")
df <- dbGetQuery(con, command) %>% mutate(dataset_name = dataset_str)
# do not consider empty datasets
if (dim(df)[1] == 0){
return(NULL)
}
# replace character NA's with NA
if (sum(is.na(df) == 0)){
df[df == "NA"] = NA
}
return(df %>% dplyr::select(-type))
}
dataset_lst <- lapply(dataset_names, query_sample, 0.3)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# cache=TRUE
con <- dbConnect(
MySQL(), host = "traffic.st47s.com", user = "student",
password = "Sagehen47", dbname = "traffic")
library(RMySQL)
library(tidyverse)
library(broom)
library(lubridate)
library(stringr)
library(kableExtra)
library(grid)
library(gridExtra)
library(patchwork)
library(XML)
library(RCurl)
library(lutz)
library(suncalc)
con <- dbConnect(
MySQL(), host = "traffic.st47s.com", user = "student",
password = "Sagehen47", dbname = "traffic")
dataset_names <- dbGetQuery(con, "SHOW TABLES")[[1]]
# remove datasets with "_" in the name
dataset_names <- dataset_names[str_detect(dataset_names, "_", negate = TRUE)]
query_sample <- function(dataset_str, percent){
# input is dataset_str (str) with dataset name, and percent (dbl) for the random sample %
# output is the dataframe with a column added for the name of dataset and character NA's
# replaced with NA's
# global variable con is the SQL connection
command <- paste("SELECT * FROM", dataset_str, "WHERE rand() <=", percent,
# in SQL, filter for vehicular stops
" AND type = 'vehicular'",
sep = " ")
df <- dbGetQuery(con, command) %>% mutate(dataset_name = dataset_str)
# do not consider empty datasets
if (dim(df)[1] == 0){
return(NULL)
}
# replace character NA's with NA
if (sum(is.na(df) == 0)){
df[df == "NA"] = NA
}
return(df %>% dplyr::select(-type))
}
dataset_lst <- lapply(dataset_names, query_sample, 0.3)
# will need to save to and load rdata when knitting so that the coefficient results are the same
# remove empty datasets through logical indexing
dataset_lst <- dataset_lst[sapply(dataset_lst, function(x) isTRUE(nrow(x) > 0))]
saveRDS(dataset_lst, file = "my_data.rds")
readRDS(file = "my_data.rds")
3+4
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# cache=TRUE
read("my_data.rds")
readRDS(file = "my_data.rds")
system("cmd.exe /C dir")
system("cmd.exe /C dir /AH")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(RMySQL)
library(tidyverse)
library(broom)
library(lubridate)
library(stringr)
library(kableExtra)
library(grid)
library(gridExtra)
library(patchwork)
library(XML)
library(RCurl)
library(lutz)
library(suncalc)
con <- dbConnect(
MySQL(), host = "traffic.st47s.com", user = "student",
password = "Sagehen47", dbname = "traffic")
dataset_names <- dbGetQuery(con, "SHOW TABLES")[[1]]
# remove datasets with "_" in the name
dataset_names <- dataset_names[str_detect(dataset_names, "_", negate = TRUE)]
query_sample <- function(dataset_str, percent){
# input is dataset_str (str) with dataset name, and percent (dbl) for the random sample %
# output is the dataframe with a column added for the name of dataset and character NA's
# replaced with NA's
# global variable con is the SQL connection
command <- paste("SELECT * FROM", dataset_str, "WHERE rand() <=", percent,
# in SQL, filter for vehicular stops
" AND type = 'vehicular'",
sep = " ")
df <- dbGetQuery(con, command) %>% mutate(dataset_name = dataset_str)
# do not consider empty datasets
if (dim(df)[1] == 0){
return(NULL)
}
# replace character NA's with NA
if (sum(is.na(df) == 0)){
df[df == "NA"] = NA
}
return(df %>% dplyr::select(-type))
}
dataset_lst <- lapply(dataset_names, query_sample, 0.2)
# will need to save to and load rdata when knitting so that the coefficient results are the same
# remove empty datasets through logical indexing
dataset_lst <- dataset_lst[sapply(dataset_lst, function(x) isTRUE(nrow(x) > 0))]
data.frame(State = c("CA", "NC", "NY", "TN", "WA"),
`Outlawing racial profiling` = c("Yes", "No", "Yes", "Yes", "Yes"),
`Use officer perception` = c("Yes", "Does not mention",  "Yes",
"Yes", "Does not mention"),
`Bill number` = c("AB 953", "GS 143B", "A03949", "HB 2167", "RCW 43.101.410")) %>%
kbl(booktabs = T, caption = "State Mandates for Traffic Stop Data Collection") %>%
kable_styling(latex_options = "hold_position")
dataset_lst[[1]]
dataset_lst[[1]]$time[1]
dataset_lst[[1]]
dataset_lst[[1]]$time[2]
round(1.3456, digits = 2)
paste(3, "3")
paste(3, "3", "%", sep = "")
paste(3, "3", "%   (", sep = "")[1:3]
substr(paste(3, "3", "%   (", sep = "")[1:3], 1, 2)
substr(paste(3, "3", "%   (", sep = ""), 1,2)
substr("2.109 (39495)", 1, 5)
as.numeric(substr("2.109 (39495)", 1, 5))
knitr::opts_chunk$set(echo = TRUE)
library(tools)
diffr("Final paper.Rmd", "hardin revisions final paper.Rmd")
md5sum("Final paper.Rmd") == md5sum("hardin revisions final paper.Rmd")
library(diffr)
install.packages("diffr")
library(diffr)
diffr("Final paper.Rmd", "hardin revisions final paper.Rmd")
knitr::opts_chunk$set(echo = TRUE)
library(RMySQL)
library(tidyverse)
library(tidyr)
# library(broom) # make tidy the regression outputs
# library(lubridate) # dates
library(stringr) # string manipulation
# library(tidycensus)
# library(kableExtra) # make nice tables
library(ggrepel)
# library(geofacet)
# library(naniar) # replace "NA" with NA, except too slow, use baseR solution
# library(revgeo)
con <- dbConnect(
MySQL(), host = "traffic.st47s.com", user = "student",
password = "insert password here :)", dbname = "insert database here :)")
con <- dbConnect(
MySQL(), host = "traffic.st47s.com", user = "student",
password = "Sagehen47", dbname = "traffic")
dataset_names <- dbGetQuery(con, "SHOW TABLES")[[1]]
# remove datasets with "_" in the name
dataset_names <- dataset_names[str_detect(dataset_names, "_", negate = TRUE)]
query_sample <- function(dataset_str, percent){
# input is dataset_str (str) with dataset name, and percent (dbl) for the random sample %
# output is the dataframe with a column added for the name of dataset and character NA's
# replaced with NA's
# global variable con is the SQL connection
command <- paste("SELECT * FROM", dataset_str, "WHERE rand() <=", percent,
# in SQL, filter for vehicular stops
" AND type = 'vehicular'",
sep = " ")
df <- dbGetQuery(con, command) %>% mutate(dataset_name = dataset_str)
# do not consider empty datasets
if (dim(df)[1] == 0){
return(NULL)
}
# replace character NA's with NA
if (sum(is.na(df) == 0)){
df[df == "NA"] = NA
}
return(df %>% dplyr::select(-type))
}
dataset_lst <- lapply(dataset_names, query_sample, 0.3)
# remove empty datasets through logical indexing
dataset_lst <- dataset_lst[sapply(dataset_lst, function(x) isTRUE(nrow(x) > 0))]
knitr::opts_chunk$set(echo = TRUE)
lapply(sc_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])
knitr::opts_chunk$set(echo = TRUE)
library(RMySQL)
library(tidyverse)
library(tidyr)
# library(broom) # make tidy the regression outputs
# library(lubridate) # dates
library(stringr) # string manipulation
# library(tidycensus)
# library(kableExtra) # make nice tables
library(ggrepel)
# library(geofacet)
# library(naniar) # replace "NA" with NA, except too slow, use baseR solution
# library(revgeo)
con <- dbConnect(
MySQL(), host = "traffic.st47s.com", user = "student",
password = "Sagehen47", dbname = "traffic")
dataset_names <- dbGetQuery(con, "SHOW TABLES")[[1]]
# remove datasets with "_" in the name
dataset_names <- dataset_names[str_detect(dataset_names, "_", negate = TRUE)]
query_sample <- function(dataset_str, percent){
# input is dataset_str (str) with dataset name, and percent (dbl) for the random sample %
# output is the dataframe with a column added for the name of dataset and character NA's
# replaced with NA's
# global variable con is the SQL connection
command <- paste("SELECT * FROM", dataset_str, "WHERE rand() <=", percent,
# in SQL, filter for vehicular stops
" AND type = 'vehicular'",
sep = " ")
df <- dbGetQuery(con, command) %>% mutate(dataset_name = dataset_str)
# do not consider empty datasets
if (dim(df)[1] == 0){
return(NULL)
}
# replace character NA's with NA
if (sum(is.na(df) == 0)){
df[df == "NA"] = NA
}
return(df %>% dplyr::select(-type))
}
dataset_lst <- lapply(dataset_names, query_sample, 0.3)
# remove empty datasets through logical indexing
dataset_lst <- dataset_lst[sapply(dataset_lst, function(x) isTRUE(nrow(x) > 0))]
check_nonempty <- function(var, dataset, n_obsv){
# helper function for removing empty columns
# the function environment has the parameter dataset
col_str <- paste("dataset$", var, sep = "")
col <- eval(parse(text = col_str))
isCollected <- sum(is.na(col)) < n_obsv
return(isCollected)
}
remove_empty_col <- function(dataset){
# a variable is 'collected' if there is a column for it in the dataset
# but being collected doesn't imply nonempty
collected_var <- names(dataset)
n_obsv <- dim(dataset)[1]
nonempty_bools <- unlist(lapply(collected_var, check_nonempty, dataset, n_obsv))
# use logial indexing!
nonempty_var <- collected_var[nonempty_bools]
## in case i need this information
# empty_var <- collected_var[!nonempty_bools]
return(dataset %>% dplyr::select({{ nonempty_var }}))
}
dataset_lst <- lapply(dataset_lst, remove_empty_col)
myfilter_for <- function(dataset, var_vect, need_containment){
# if need_containment is true, then function only returns
# datasets containing ALL variables specified in var_vect
# need_containment = TRUE results in more restrictive filtering
dataset_var <- names(dataset)
intersection <- var_vect[var_vect %in% dataset_var]
if (need_containment){
if (length(intersection) == length(var_vect)) {
# embrace syntax from dplyr programming
return(dataset %>% dplyr::select({{ var_vect }}))
} else {
return(NULL)
}
} else if (!need_containment){
if (length(intersection > 0)) {
# embrace syntax from dplyr programming
return(dataset %>% dplyr::select({{ intersection }}))
} else{
return(NULL)
}
}
}
sc_dataset_lst <- lapply(dataset_lst, myfilter_for, c("search_conducted"), TRUE)
sc_dataset_lst <- sc_dataset_lst[sapply(sc_dataset_lst,
function(x) isTRUE(nrow(x) > 0))]
lapply(sc_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])
unlist(lapply(sc_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
sc_dataset_lst[7]$dataset_name
sc_dataset_lst[7]
sc_dataset_lst <- lapply(dataset_lst, myfilter_for, c("search_conducted", "dataset_name"), TRUE)
unlist(lapply(sc_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
sc_dataset_lst[7]
unlist(lapply(sc_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
sc_dataset_lst <- lapply(dataset_lst, myfilter_for, c("arrest_made", "dataset_name"), TRUE)
sc_dataset_lst <- sc_dataset_lst[sapply(sc_dataset_lst,
function(x) isTRUE(nrow(x) > 0))]
ar_dataset_lst <- lapply(dataset_lst, myfilter_for, c("arrest_made", "dataset_name"), TRUE)
at_dataset_lst <- ar_dataset_lst[sapply(ar_dataset_lst,
function(x) isTRUE(nrow(x) > 0))]
unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
data.frame(unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])))
histogram(unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])))
hist(unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])))
unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
ar_dataset_lst <- lapply(dataset_lst, myfilter_for, c("arrest_made", "dataset_name"), TRUE)
ar_dataset_lst <- ar_dataset_lst[sapply(ar_dataset_lst,
function(x) isTRUE(nrow(x) > 0))]
hist(unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])))
unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
race_dataset_lst <- lapply(dataset_lst, myfilter_for, c("arrest_made", "dataset_name"), TRUE)
race_dataset_lst <- race_dataset_lst[sapply(race_dataset_lst,
function(x) isTRUE(nrow(x) > 0))]
hist(unlist(lapply(race_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])))
unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
lapply(dataset_lst, function(x) names(x))
race_dataset_lst <- lapply(dataset_lst, myfilter_for, c("driver_race", "dataset_name"), TRUE)
race_dataset_lst <- race_dataset_lst[sapply(race_dataset_lst,
function(x) isTRUE(nrow(x) > 0))]
race_dataset_lst <- lapply(dataset_lst, myfilter_for, c("subject_race", "dataset_name"), TRUE)
race_dataset_lst <- race_dataset_lst[sapply(race_dataset_lst,
function(x) isTRUE(nrow(x) > 0))]
rm(at_dataset_lst)
hist(unlist(lapply(race_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])))
unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))
sum(unlist(lapply(ar_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])) >= 0.2)
sum(unlist(lapply(race_dataset_lst, function(x) sum(is.na(x))/dim(x)[1])) >= 0.2)
sum(unlist(lapply(sc_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))>= 0.2)
sapply(sc_dataset_lst, function(x) ifelse(x$search_conducted >= 0.2, x$dataset_name, 0))
sapply(sc_dataset_lst, function(x) return(ifelse(x$search_conducted >= 0.2, x$dataset_name, 0)))
sapply(sc_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, x$dataset_name, "nah"))
sapply(sc_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, c(x$dataset_name. dim(x)), "nah"))
sapply(sc_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, c(x$dataset_name. dim(x)[1]), "nah"))
sapply(sc_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, c(x$dataset_name. as_str(dim(x)[1])), "nah"))
sapply(sc_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, c(x$dataset_name, as.character(dim(x)[1])), "nah"))
sapply(sc_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, c(as.character(dim(x)[1])), "nah"))
sapply(sc_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, paste(x$dataset_name, as.character(dim(x)[1])), "nah"))
934604+251264+1152790
sum(unlist(lapply(race_dataset_lst, function(x) sum(is.na(x))/dim(x)[1]))>= 0.2)
sapply(race_dataset_lst, function(x) ifelse(sum(is.na(x))/dim(x)[1] >= 0.2, paste(x$dataset_name, as.character(dim(x)[1])), "nah"))
572941+623317+251264+78265+1153790+22073+94063
